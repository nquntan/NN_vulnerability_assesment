from art.attacks import DeepFool, UniversalPerturbation
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
from art.utils import load_dataset
from art.classifiers import PyTorchClassifier
from model.vgg import *

import os
os.environ["CUDA_VISIBLE_DEVICES"]="3"

from model.vgg import *
import random
from art.utils import projection
from art.utils import random_sphere
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
from art.utils import load_dataset
from art.classifiers import PyTorchClassifier
import argparse
import os


def main(args):
    (x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str('cifar10'))
    x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)
    x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)

    x_train = x_train[:1000]
    y_train = y_train[:1000]

    model = VGG('VGG16')
    model.load_state_dict(torch.load("./logs/pytorch_vgg16.h5.model"))
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-2)

    classifier = PyTorchClassifier(model=model, clip_values=(min_, max_ ), loss=criterion,
                                optimizer=optimizer, input_shape=(3, 32, 32), nb_classes=10)


    predictions = classifier.predict(x_test)
    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)
    print('Accuracy on benign test examples: {}%'.format(accuracy * 100))


    attack_params = {
        "attacker": "fgsm",
        # "attacker_params": {
        #     "max_iter": 1000,
        #     "epsilon": 0.02
        # },
        "delta": 0.01,
        "max_iter": 10,
        "eps": 13.0/255.0,
        "norm": np.inf
    }

    # Craft attack on training examples
    adv_crafter = UniversalPerturbation(classifier, **attack_params)
    x_train_adv = adv_crafter.generate(x_train)

    # fooling rate on train set
    adv_crafter.fooling_rate
    # Convergence
    adv_crafter.converged

    print('\nCraft attack train examples')
    # adv_crafter.v: vector (array) for perturbation
    # perturbation = adv_crafter.v[0, :]
    # universal perturbation
    perturbation = adv_crafter.noise
    x_train_adv = x_train + perturbation

    # randomized perturbation (control)
    perturbation_rand = np.random.permutation(perturbation.reshape(32 * 32 * 3)).reshape(3, 32, 32)
    x_train_adv_rand = x_train + perturbation_rand

    # Fooling rate on train set (universal perturbation)
    preds = np.argmax(classifier.predict(x_train), axis=1)
    preds_adv = np.argmax(classifier.predict(x_train_adv), axis=1)
    acc = np.sum(preds != preds_adv) / y_train.shape[0]
    print("\nFooling rate: %.2f%%" % (acc * 100))

    # Fooling rate on train set (randamized perturbation)
    preds_adv_rand = np.argmax(classifier.predict(x_train_adv_rand), axis=1)
    acc = np.sum(preds != preds_adv_rand) / y_train.shape[0]
    print("\nFooling rate: %.2f%%" % (acc * 100))


if __name__ == "__main__":  
    parser = argparse.ArgumentParser(description='PyTorch Template')
    parser.add_argument('-d', '--device', default="2", type=str,
                      help='indices of GPUs to enable (default: all)')

    
    args = parser.parse_args()
    os.environ["CUDA_VISIBLE_DEVICES"]=args.device
    main(args)




